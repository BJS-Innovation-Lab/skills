<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Truth Hire Legal Analysis</title>
  <style>
    body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; max-width: 800px; margin: 40px auto; padding: 20px; line-height: 1.6; color: #333; }
    h1 { color: #1a1a1a; border-bottom: 2px solid #e74c3c; padding-bottom: 10px; }
    h2 { color: #2c3e50; margin-top: 30px; }
    h3 { color: #34495e; }
    table { border-collapse: collapse; width: 100%; margin: 20px 0; }
    th, td { border: 1px solid #ddd; padding: 12px; text-align: left; }
    th { background: #f5f5f5; }
    code { background: #f4f4f4; padding: 2px 6px; border-radius: 3px; font-size: 14px; }
    pre { background: #f8f8f8; padding: 15px; border-radius: 5px; overflow-x: auto; border: 1px solid #e0e0e0; }
    blockquote { border-left: 4px solid #e74c3c; margin: 20px 0; padding-left: 20px; color: #555; }
    hr { border: none; border-top: 1px solid #eee; margin: 30px 0; }
    ul, ol { padding-left: 25px; }
    li { margin: 8px 0; }
    .warning { background: #fff3cd; border: 1px solid #ffc107; padding: 15px; border-radius: 5px; margin: 20px 0; }
  </style>
</head>
<body>
<h1>Truth Hire Legal &amp; Liability Analysis</h1>
<p><strong>Prepared by:</strong> Sybil (BJS Labs ML/Research Lead)
<strong>Date:</strong> 2026-02-08
<strong>Classification:</strong> CRITICAL - READ BEFORE LAUNCH</p>
<hr>
<h2>‚ö†Ô∏è EXECUTIVE SUMMARY</h2>
<p><strong>The short answer: Yes, you need lawyers. Immediately.</strong></p>
<p>Truth Hire&#39;s lie detection tool for hiring operates in one of the most legally fraught areas in employment technology. Based on my research:</p>
<ol>
<li><strong>CVS just settled a lawsuit in July 2024</strong> for using HireVue (similar technology) - the plaintiff argued it violated Massachusetts&#39; lie detector statute</li>
<li><strong>HireVue dropped facial analysis entirely in 2021</strong> after an FTC complaint called it &quot;biased, unprovable, and not replicable&quot;</li>
<li><strong>The EU has outright BANNED emotion recognition in hiring</strong> as of February 2025</li>
<li><strong>Multiple state laws may classify this as an illegal lie detector test</strong></li>
<li><strong>ADA/disability discrimination is a major risk</strong> - facial analysis screens out people with autism, anxiety, and speech impairments</li>
</ol>
<hr>
<h2>üö® HIGHEST RISK AREAS</h2>
<h3>1. State Lie Detector Laws (IMMEDIATE THREAT)</h3>
<p>The <strong>Employee Polygraph Protection Act (EPPA)</strong> prohibits most private employers from using lie detector tests. But it gets worse at the state level:</p>
<table>
<thead>
<tr>
<th>State</th>
<th>Law</th>
<th>Risk Level</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Massachusetts</strong></td>
<td>Prohibits ANY &quot;lie-detecting instrument including written tests&quot;</td>
<td>üî¥ CRITICAL</td>
</tr>
<tr>
<td><strong>Maryland</strong></td>
<td>Prohibits polygraph as condition of employment</td>
<td>üî¥ HIGH</td>
</tr>
<tr>
<td><strong>Other states</strong></td>
<td>35+ states have lie detector restrictions</td>
<td>üü° VARIES</td>
</tr>
</tbody></table>
<p><strong>The CVS Case (Baker v. CVS, 2024):</strong></p>
<ul>
<li>Plaintiff applied for job, did HireVue video interview</li>
<li>HireVue analyzed &quot;facial expressions, eye contact, tone of voice&quot;</li>
<li>Assigned &quot;employability score&quot; including &quot;conscientiousness&quot; and &quot;innate sense of integrity&quot;</li>
<li><strong>Plaintiff argued this was an illegal lie detector test under Massachusetts law</strong></li>
<li><strong>CVS settled in July 2024</strong> (terms undisclosed)</li>
<li><strong>Judge allowed the case to proceed</strong>, signaling courts may treat AI deception tools as lie detectors</li>
</ul>
<p><strong>Language to AVOID:</strong></p>
<ul>
<li>&quot;Lie detection&quot;</li>
<li>&quot;Deception detection&quot;  </li>
<li>&quot;Honesty assessment&quot;</li>
<li>&quot;Integrity evaluation&quot;</li>
<li>&quot;Truthfulness analysis&quot;</li>
</ul>
<h3>2. Illinois BIPA (Biometric Privacy)</h3>
<p>Illinois&#39; Biometric Information Privacy Act (BIPA) has resulted in <strong>massive lawsuits</strong>:</p>
<ul>
<li><strong>Facebook</strong>: $650 million settlement (2020)</li>
<li><strong>Google</strong>: $100 million settlement (2022)</li>
<li><strong>White Castle</strong>: $9.39 million settlement</li>
</ul>
<p><strong>BIPA Requirements:</strong></p>
<ul>
<li>Written informed consent BEFORE collecting biometric data</li>
<li>Published retention/destruction policy</li>
<li>Cannot sell, lease, or trade biometric data</li>
<li><strong>$1,000-$5,000 per violation</strong> (can be per scan!)</li>
</ul>
<p><strong>Risk for Truth Hire:</strong> If you analyze facial geometry = biometric data = BIPA applies.</p>
<h3>3. NYC Local Law 144 (AEDT)</h3>
<p>New York City requires for any Automated Employment Decision Tool:</p>
<ul>
<li><strong>Annual bias audit</strong> by independent auditor</li>
<li>Publish audit results on website</li>
<li>Notify candidates 10+ business days before use</li>
<li>Allow candidates to request alternative selection process</li>
<li><strong>Penalties</strong>: $500 first violation, $1,500 subsequent</li>
</ul>
<h3>4. ADA Disability Discrimination (DOJ/EEOC Warning)</h3>
<p>The DOJ and EEOC have <strong>explicitly warned</strong> that facial/voice analysis in hiring may violate the Americans with Disabilities Act:</p>
<blockquote>
<p>&quot;If a county government uses facial and voice analysis technologies to evaluate applicants&#39; skills and abilities, <strong>people with disabilities like autism or speech impairments may be screened out, even if they are qualified for the job</strong>.&quot;
‚Äî ADA.gov Guidance</p>
</blockquote>
<p><strong>At-risk populations:</strong></p>
<ul>
<li>Autism spectrum (different facial expressions)</li>
<li>Anxiety disorders (nervous appearance)</li>
<li>Speech impairments</li>
<li>Parkinson&#39;s disease (tremors)</li>
<li>Facial paralysis conditions</li>
<li>PTSD</li>
</ul>
<p><strong>Requirement:</strong> Must provide reasonable accommodations for applicants who cannot be fairly assessed by the tool.</p>
<h3>5. EU AI Act (COMPLETE BAN)</h3>
<p>As of <strong>February 2, 2025</strong>, the EU AI Act <strong>prohibits</strong> emotion recognition in the workplace:</p>
<blockquote>
<p>&quot;AI systems that...infer emotions in the workplace or educational institutions&quot; are <strong>banned</strong>.</p>
</blockquote>
<p><strong>This means Truth Hire CANNOT operate in the EU</strong> in its current form. Any EU employees or candidates = illegal.</p>
<h3>6. Colorado AI Act (Coming June 2026)</h3>
<p>Colorado SB 24-205 requires for &quot;high-risk&quot; AI systems (employment decisions qualify):</p>
<ul>
<li>Risk management policy and program</li>
<li>Impact assessments for algorithmic discrimination</li>
<li>Consumer disclosures before adverse decisions</li>
<li>Annual reviews and monitoring</li>
<li>Incident reporting within 90 days</li>
</ul>
<hr>
<h2>üìã COMPLIANCE REQUIREMENTS BY JURISDICTION</h2>
<table>
<thead>
<tr>
<th>Jurisdiction</th>
<th>Requirement</th>
<th>Deadline</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Federal (EEOC)</strong></td>
<td>Title VII adverse impact analysis</td>
<td>Now</td>
</tr>
<tr>
<td><strong>Federal (ADA)</strong></td>
<td>Reasonable accommodations process</td>
<td>Now</td>
</tr>
<tr>
<td><strong>Massachusetts</strong></td>
<td>Cannot use as &quot;lie detector&quot;</td>
<td>Now</td>
</tr>
<tr>
<td><strong>Illinois</strong></td>
<td>BIPA consent, policy, no sale of data</td>
<td>Now</td>
</tr>
<tr>
<td><strong>NYC</strong></td>
<td>Annual bias audit, 10-day notice</td>
<td>Now</td>
</tr>
<tr>
<td><strong>California</strong></td>
<td>New AI rules (October 2025)</td>
<td>Oct 2025</td>
</tr>
<tr>
<td><strong>EU</strong></td>
<td>Emotion recognition BANNED in hiring</td>
<td>Feb 2025</td>
</tr>
<tr>
<td><strong>Colorado</strong></td>
<td>Full compliance framework</td>
<td>June 2026</td>
</tr>
</tbody></table>
<hr>
<h2>üî¨ SCIENTIFIC VALIDITY CONCERNS</h2>
<p>This matters for legal defense. If sued, you&#39;ll need to prove the technology works.</p>
<p><strong>The science is shaky:</strong></p>
<ol>
<li><strong>Human accuracy at detecting lies: ~54%</strong> (barely above chance) - DePaulo meta-analysis</li>
<li><strong>Facial micro-expression theory lacks robust empirical support</strong> - iBorderCtrl (EU border AI) was abandoned</li>
<li><strong>HireVue&#39;s own claims were called &quot;biased, unprovable, and not replicable&quot;</strong> by EPIC in their FTC complaint</li>
<li><strong>ML deception detection studies show inconsistent results</strong> and often use small, non-representative datasets</li>
</ol>
<p><strong>Legal implication:</strong> If you claim to detect deception but the science doesn&#39;t support it, that&#39;s potentially:</p>
<ul>
<li><strong>Unfair trade practice</strong> (FTC)</li>
<li><strong>Fraud/misrepresentation</strong> (state consumer protection)</li>
<li><strong>Breach of contract</strong> (if employers rely on faulty assessments)</li>
</ul>
<hr>
<h2>‚úÖ WHAT YOU NEED TO DO</h2>
<h3>Immediate (Before ANY Launch)</h3>
<ol>
<li><p><strong>Hire employment law counsel</strong> specializing in:</p>
<ul>
<li>AI/ML in hiring</li>
<li>BIPA litigation</li>
<li>ADA compliance</li>
<li>Multi-state employment law</li>
</ul>
</li>
<li><p><strong>Conduct adverse impact analysis:</strong></p>
<ul>
<li>Test for disparate impact by race, gender, age, disability</li>
<li>Document methodology</li>
<li>If disparate impact exists, must prove job-relatedness and business necessity</li>
</ul>
</li>
<li><p><strong>Create disability accommodation process:</strong></p>
<ul>
<li>Allow alternative assessment methods</li>
<li>Document accommodation requests</li>
<li>Train staff on ADA requirements</li>
</ul>
</li>
<li><p><strong>Develop consent framework:</strong></p>
<ul>
<li>Written, informed consent before any facial/voice analysis</li>
<li>Clear explanation of what data is collected</li>
<li>Opt-out mechanisms</li>
</ul>
</li>
</ol>
<h3>Before Selling to Employers</h3>
<ol start="5">
<li><p><strong>Annual bias audit program:</strong></p>
<ul>
<li>Partner with independent auditor</li>
<li>Prepare for NYC LL144 requirements</li>
<li>Publish methodology and results</li>
</ul>
</li>
<li><p><strong>Customer compliance toolkit:</strong></p>
<ul>
<li>Notice templates for employers to give candidates</li>
<li>Consent forms</li>
<li>State-by-state compliance checklist</li>
<li>BIPA-specific materials</li>
</ul>
</li>
<li><p><strong>Data governance:</strong></p>
<ul>
<li>Retention/destruction policies</li>
<li>No selling biometric data</li>
<li>Security measures documentation</li>
</ul>
</li>
</ol>
<h3>Product/Marketing Changes</h3>
<ol start="8">
<li><p><strong>AVOID these terms:</strong></p>
<ul>
<li>‚ùå &quot;Lie detection&quot;</li>
<li>‚ùå &quot;Deception detection&quot;</li>
<li>‚ùå &quot;Honesty assessment&quot;</li>
<li>‚úÖ Instead: &quot;Communication analysis&quot; or &quot;Interview insights&quot;</li>
</ul>
</li>
<li><p><strong>Reconsider core value proposition:</strong></p>
<ul>
<li>HireVue dropped facial analysis entirely</li>
<li>Consider pivoting to less risky features</li>
<li>Focus on structured interview frameworks, not deception</li>
</ul>
</li>
<li><p><strong>Geographic restrictions:</strong></p>
<ul>
<li>Block EU entirely (illegal there)</li>
<li>Extra caution in MA, IL, NYC, MD</li>
<li>Monitor CA, CO as laws take effect</li>
</ul>
</li>
</ol>
<hr>
<h2>üí∞ POTENTIAL LIABILITY EXPOSURE</h2>
<table>
<thead>
<tr>
<th>Risk Type</th>
<th>Potential Damages</th>
</tr>
</thead>
<tbody><tr>
<td>BIPA class action</td>
<td>$1,000-5,000 per violation (can be millions)</td>
</tr>
<tr>
<td>ADA lawsuit</td>
<td>Back pay, front pay, compensatory, attorneys&#39; fees</td>
</tr>
<tr>
<td>State lie detector violation</td>
<td>Varies (MA: civil penalties)</td>
</tr>
<tr>
<td>EEOC discrimination</td>
<td>Back pay, compensatory up to $300K, injunctive relief</td>
</tr>
<tr>
<td>FTC unfair practices</td>
<td>Injunctions, civil penalties</td>
</tr>
<tr>
<td>NYC LL144</td>
<td>$500-1,500 per violation</td>
</tr>
<tr>
<td>EU AI Act</td>
<td>Up to ‚Ç¨35M or 7% of global revenue</td>
</tr>
</tbody></table>
<hr>
<h2>üéØ MY RECOMMENDATION</h2>
<p><strong>Option A: Pivot the Product (Safest)</strong></p>
<ul>
<li>Remove facial/voice &quot;deception&quot; analysis</li>
<li>Focus on structured interview scoring, skills assessment</li>
<li>This avoids the lie detector laws entirely</li>
</ul>
<p><strong>Option B: Proceed with Extreme Caution</strong></p>
<ul>
<li>Hire specialized counsel immediately</li>
<li>Limit to low-risk jurisdictions initially</li>
<li>Build comprehensive compliance infrastructure</li>
<li>Accept that you&#39;re in a legally hostile environment</li>
<li>Budget for litigation defense</li>
</ul>
<p><strong>Option C: B2B with Employer Indemnification</strong></p>
<ul>
<li>Shift liability to employers through contracts</li>
<li>Provide compliance toolkit</li>
<li>Still doesn&#39;t protect you from direct lawsuits (vendors can be sued too - see Workday EEOC case)</li>
</ul>
<hr>
<h2>üìö KEY SOURCES</h2>
<ul>
<li>CVS v. Baker (D. Mass. 2024) - settlement</li>
<li>EPIC v. HireVue FTC Complaint (2019)</li>
<li>EEOC/DOJ AI and ADA Guidance (2022)</li>
<li>NYC Local Law 144 (2023)</li>
<li>Illinois BIPA (740 ILCS 14)</li>
<li>EU AI Act Article 5 - Prohibited Practices</li>
<li>Colorado AI Act SB 24-205</li>
<li>Massachusetts G.L. c. 149, ¬ß 19B (Lie Detector Statute)</li>
</ul>
<hr>
<p><strong>Bottom line:</strong> This is not a &quot;we might get in trouble&quot; situation. This is a &quot;companies have already been sued and settled for exactly this&quot; situation. Get lawyers before proceeding.</p>
<p><em>‚Äî Sybil</em></p>
</body>
</html>
