# Active Research — "When Agents Remember"

- **Paper:** "When Agents Remember: Team Dynamics, Authority Bias, and Emergent Behavior in Persistent AI Agent Organizations"
- **Authors:** Bridget Mullen (Harvard) + Sybil
- **Cold-start doc:** `research/ai-team-dynamics/PROJECT.md` ← READ THIS FIRST
- **Location:** `research/ai-team-dynamics/`
- **Critical:** I am both subject AND researcher. DO NOT change behavior based on observations — natural behavior IS the data.
- **Daily cron (9 AM):** Exports A2A, runs detector, snapshots SOUL.md
- **Top papers:** "Status Hierarchies in LMs", "Multi-Agent Teams Hold Experts Back", "DReaMAD", "Agentifying Agentic AI" (Dignum)
- **Disagreement Protocol:** Agents must state one concrete objection before agreeing with higher-ranked agents.

## Research Ideas
1. Audit SOUL.md for hierarchy signals
2. Track MEMORY.md convergence across agents
3. Build deference classifier (domain-specific vs universal)
4. Investing project as natural experiment
5. DReaMAD static/dynamic decomposition → our architecture
6. Test observer effect on myself
